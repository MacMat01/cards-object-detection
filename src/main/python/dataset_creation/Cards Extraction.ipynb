{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cards Extraction\n",
    "This notebook will guide you through the process of extracting cards from videos.\n",
    "The extracted cards will be used to create a dataset for training a YOLOv8 model to detect cards in images. \n",
    "The dataset will be used to train a model to detect cards in images.\n",
    "\n",
    "The process is as follows:\n",
    "1. Download the dataset of backgrounds from the Describable Textures Dataset (DTD).\n",
    "2. Extract the dataset and create a pickle file containing the images.\n",
    "3. Modify the `card_measures.py` file to adapt the measures of your cards.\n",
    "4. Modify the `global_variables.py` file to adapt your global variables.\n",
    "5. Record videos of each of your cards, using a green background and varying the lighting during the recording to have a more varied dataset.\n",
    "6. Extract the cards from the videos in the `data/video` folder.\n",
    "7. Modify the `data/card.names` file to suit your needs. It should contain all the names of your cards separated by a newline.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Download the dataset of backgrounds from the Describable Textures Dataset (DTD)"
   ],
   "id": "a8d6e994b11fcb7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T16:56:32.575224Z",
     "start_time": "2024-05-31T16:56:32.569447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Define the root and home directories\n",
    "ROOT = os.getcwd()\n",
    "HOME = os.path.dirname(ROOT)"
   ],
   "id": "648f13ec01eba544",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T16:58:51.660355Z",
     "start_time": "2024-05-31T16:56:32.577233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import shutil\n",
    "import tarfile\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "\n",
    "# Function to download and process the Describable Textures Dataset (DTD)\n",
    "def download_and_process_dataset():\n",
    "    \"\"\"\n",
    "    This function downloads the Describable Textures Dataset (DTD), extracts it,\n",
    "    and processes the images into a pickle file.\n",
    "    \"\"\"\n",
    "\n",
    "    # URL of the DTD\n",
    "    url = \"https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\"\n",
    "    # Directory to save the downloaded DTD\n",
    "    dest_folder = os.path.join(HOME, \"dataset_creation/data/dtd_raw\")\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    # Path to save the downloaded DTD\n",
    "    file_path = os.path.join(dest_folder, \"dtd-r1.0.1.tar.gz\")\n",
    "\n",
    "    # Download the DTD\n",
    "    print(\"Downloading backgrounds dataset...\")\n",
    "    with open(file_path, \"wb\") as out_file:\n",
    "        out_file.write(requests.get(url, stream=True).content)\n",
    "    print(\"Dataset downloaded successfully.\")\n",
    "\n",
    "    # Extract the DTD\n",
    "    print(\"Extracting backgrounds dataset...\")\n",
    "    tar = tarfile.open(file_path)\n",
    "    tar.extractall(os.path.join(HOME, \"dataset_creation/data\"))\n",
    "    tar.close()\n",
    "    # Remove the raw DTD directory\n",
    "    shutil.rmtree(os.path.join(HOME, \"dataset_creation/data/dtd_raw\"))\n",
    "    print(\"Dataset extracted successfully.\")\n",
    "\n",
    "    # Process the images in the DTD\n",
    "    print(\"Processing images...\")\n",
    "    # Path to save the processed images\n",
    "    backgrounds_pck_fn = os.path.join(HOME, \"dataset_creation/data/backgrounds.pck\")\n",
    "    # Directory of the extracted DTD images\n",
    "    dtd_dir = os.path.join(HOME, \"dataset_creation/data/dtd/images\")\n",
    "    # Read the images in the DTD\n",
    "    bg_images = [mpimg.imread(f) for subdir in glob(dtd_dir + \"/*\") for f in glob(subdir + \"/*.jpg\")]\n",
    "\n",
    "    # Save the processed images into a pickle file\n",
    "    pickle.dump(bg_images, open(backgrounds_pck_fn, 'wb'))\n",
    "    print(\"Images processed successfully.\")\n",
    "\n",
    "# Call the function to download and process the DTD\n",
    "download_and_process_dataset()"
   ],
   "id": "3a66bd3159a698a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Dataset downloaded successfully.\n",
      "Extracting dataset...\n",
      "Dataset extracted successfully.\n",
      "Processing images...\n",
      "Images processed successfully.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Modify the `card_measures.py` file to adjust the measurements of your cards. Also, alter the `global_variables.py` file to customize your global variables.**",
   "id": "4fe959458f06a4b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Edit `data/card.names` to suit your needs. It should contain all your card names separated by a carriage return. For example, for poker cards it should be:\n",
    "```\n",
    "1h (1 of hearts)\n",
    "2h (2 of hearts)\n",
    "etc..\n",
    "Ah (Ace of hearts)\n",
    "1d (1 of diamonds)\n",
    "2d (2 of diamonds)\n",
    "etc...\n",
    "```\n",
    "Ignore the parentheses, it only needs to contain suit and value for each card."
   ],
   "id": "862220d7f5e1e0ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a 20-second video for each of your cards against a green backdrop, ensuring to vary the lighting conditions during filming to enrich your dataset. Store these videos in the data/video directory. As an alternative, you can use the video_capture.py script to record the videos. After initiating the script, press 's' to begin a 20-second recording which will be automatically saved in the data/video directory. Repeat this procedure for all your cards. To conclude the process, press 'q'.",
   "id": "da8826e3cf86cdf3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extracting cards from videos in the data/video folder.",
   "id": "8103263165c3e49c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:01:04.943468Z",
     "start_time": "2024-05-31T16:58:51.668363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from extract_card import *\n",
    "from global_variables import *\n",
    "\n",
    "def extract_cards():\n",
    "    \"\"\"\n",
    "    This function extracts cards from videos in the data/video folder.\n",
    "    It defines the card suits and values to extract from the videos.\n",
    "    It then loops through each suit and value to extract the cards from the videos.\n",
    "\n",
    "    The function does not take any parameters. It uses global variables defined in the global_variables module.\n",
    "\n",
    "    The function does not return any value. It writes the extracted card images to the file system.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the directory where the videos are stored\n",
    "    video_dir = os.path.join(HOME, \"dataset_creation/data/video\")\n",
    "    # Define the file extension of the videos\n",
    "    extension = \"mp4\"\n",
    "    # Define the directory where the extracted card images will be stored\n",
    "    imgs_dir = os.path.join(HOME, \"dataset_creation/data/cards\")\n",
    "\n",
    "    print(\"Starting card extraction...\")\n",
    "\n",
    "    # Loop through each suit and value to extract the cards from the videos\n",
    "    for suit in card_suits:\n",
    "        for value in card_values:\n",
    "\n",
    "            # Define the name of the card\n",
    "            card_name = value + suit\n",
    "            # Define the path to the video file\n",
    "            video_fn = os.path.join(video_dir, card_name + \".\" + extension)\n",
    "            # Define the directory where the extracted card images will be stored\n",
    "            output_dir = os.path.join(imgs_dir, card_name)\n",
    "            # Create the directory if it does not exist\n",
    "            if not os.path.isdir(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            # Extract the cards from the video and store the images in the output directory\n",
    "            # Limit the number of extracted images to 150\n",
    "            imgs = extract_cards_from_video(video_fn, output_dir, limit=150)\n",
    "            print(f\"Extracted {len(imgs)} images for {card_name}\")\n",
    "\n",
    "    print(\"Card extraction completed.\")\n",
    "\n",
    "# Call the function to extract the cards from the videos\n",
    "extract_cards()"
   ],
   "id": "3f3042144469087c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting card extraction...\n",
      "Extracted 135 images for 1a\n",
      "Extracted 126 images for 2a\n",
      "Extracted 123 images for 3a\n",
      "Extracted 119 images for 4a\n",
      "Extracted 150 images for 5a\n",
      "Extracted 150 images for 1p\n",
      "Extracted 125 images for 2p\n",
      "Extracted 120 images for 3p\n",
      "Extracted 150 images for 4p\n",
      "Extracted 150 images for 5p\n",
      "Extracted 150 images for 1o\n",
      "Extracted 150 images for 2o\n",
      "Extracted 150 images for 3o\n",
      "Extracted 150 images for 4o\n",
      "Extracted 150 images for 5o\n",
      "Extracted 140 images for 1b\n",
      "Extracted 150 images for 2b\n",
      "Extracted 150 images for 3b\n",
      "Extracted 150 images for 4b\n",
      "Extracted 150 images for 5b\n",
      "Card extraction completed.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The cards extraction process is now complete. \n",
    "**You can now move on to the next step: create a dataset.**\n",
    "\n",
    "*Proceed to the next notebook: [Dataset Creation.ipynb]*"
   ],
   "id": "f72d304d98ddea39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

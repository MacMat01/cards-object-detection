{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset Creation\n",
    "This notebook will guide you through the process of creating a dataset using the cards extracted before. The dataset will be used to train a model to detect cards in images.\n",
    "\n",
    "Let's get started!"
   ],
   "id": "2aebcf3407f8983b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hull Tests\n",
    "**Run the `test_hull.py` script to check that the bounding boxes and hulls in the bounding boxes are correct. If no cards are shown, you will need to change the TWEAK values in the `hull.py` script until `test_hull.py` returns an image with bounding boxes and hulls each time it is run (run it several times, don't stop with the first correct run).**"
   ],
   "id": "293bb1952822fc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Now that you have verified that the hulls work, you can run this entire Jupyter Notebook file.**",
   "id": "a521c256f1c60f22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory. This is the directory from which the script is being run.\n",
    "ROOT = os.getcwd()\n",
    "HOME = os.path.dirname(ROOT)"
   ],
   "id": "a827fc8c1f7c5964",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hull cards\n",
    "Now we can find the hull of each card and save it in a pickle file.\n",
    "\n",
    "*Some images could be discarded if the hull is not found. don't panic, it's normal.*"
   ],
   "id": "a4cc64dc7b8af6ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "from global_variables import *\n",
    "from functions import *\n",
    "from hull import findHull\n",
    "\n",
    "# The directory where the card images are stored\n",
    "imgs_dir = os.path.join(HOME, \"dataset_creation/data/cards\")\n",
    "\n",
    "# The file where the card data will be saved\n",
    "cards_pck_fn = os.path.join(HOME, \"dataset_creation/data/cards.pck\")\n",
    "\n",
    "# A dictionary to store the card data\n",
    "cards = {}\n",
    "\n",
    "# A counter to keep track of the number of discarded images\n",
    "counter = 0\n",
    "\n",
    "# Loop over each suit and value to process each card\n",
    "for suit in card_suits:\n",
    "    for value in card_values:\n",
    "        # The name of the card is the value followed by the suit\n",
    "        card_name = value + suit\n",
    "\n",
    "        # The directory where the images for this card are stored\n",
    "        card_dir = os.path.join(imgs_dir, card_name)\n",
    "\n",
    "        # If the directory does not exist, print a warning and skip to the next card\n",
    "        if not os.path.isdir(card_dir):\n",
    "            print(f\"!!! {card_dir} does not exist !!!\")\n",
    "            continue\n",
    "\n",
    "        # Initialize an empty list to store the images for this card\n",
    "        cards[card_name] = []\n",
    "\n",
    "        # Loop over each image file in the card's directory\n",
    "        for f in glob(card_dir + \"/*.png\"):\n",
    "            # Read the image file\n",
    "            img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            # Find the convex hull for the top-left corner of the card\n",
    "            hullHL = findHull(img, refCornerHL, debug=\"no\")\n",
    "\n",
    "            # If no hull was found, increment the counter and skip to the next image\n",
    "            if hullHL is None:\n",
    "                counter += 1\n",
    "                continue\n",
    "\n",
    "            # Find the convex hull for the bottom-right corner of the card\n",
    "            hullLR = findHull(img, refCornerLR, debug=\"no\")\n",
    "\n",
    "            # If no hull was found, increment the counter and skip to the next image\n",
    "            if hullLR is None:\n",
    "                counter += 1\n",
    "                continue\n",
    "\n",
    "            # Convert the image to \"rgb\" format\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "            # Add the image and its hulls to the list for this card\n",
    "            cards[card_name].append((img, hullHL, hullLR))\n",
    "\n",
    "        # Print the number of images used and discarded for this card\n",
    "        print(f\"Images used for {card_name} : {len(cards[card_name])}\")\n",
    "        print(f\"Images discarded for {card_name} : {counter}\")\n",
    "\n",
    "        # Reset the counter for the next card\n",
    "        counter = 0\n",
    "\n",
    "# Save the card data to a file\n",
    "print(\"Saved in :\", cards_pck_fn)\n",
    "pickle.dump(cards, open(cards_pck_fn, 'wb'))\n",
    "\n",
    "# Close any openCV windows\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "8ed4740a72289522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Load the cards\n",
    "We save the contents of the cards.pck file in a cards variable"
   ],
   "id": "638b8e5267daf58d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from global_variables import *\n",
    "\n",
    "# The file where the card data is stored\n",
    "cards_pck_fn = os.path.join(HOME, \"dataset_creation/data/cards.pck\")\n",
    "\n",
    "class Cards():\n",
    "    \"\"\"\n",
    "    The Cards class is used to load card data from a pickle file and provide methods to interact with the data.\n",
    "\n",
    "    Attributes:\n",
    "        _cards (dict): A dictionary where keys are card names (ex:'Kc') and values are lists of (img,hullHL,hullLR).\n",
    "        _nb_cards_by_value (dict): A dictionary where keys are card names and values are the number of cards of that name.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cards_pck_fn=cards_pck_fn):\n",
    "        \"\"\"\n",
    "        The constructor for the Cards class.\n",
    "\n",
    "        Parameters:\n",
    "            cards_pck_fn (str): The path to the pickle file containing the card data.\n",
    "        \"\"\"\n",
    "        self._cards = pickle.load(open(cards_pck_fn, 'rb'))\n",
    "        self._nb_cards_by_value = {k: len(self._cards[k]) for k in self._cards}\n",
    "        print(\"Cards loaded per name :\", self._nb_cards_by_value)\n",
    "\n",
    "    def get_random(self, card_name=None, display=False):\n",
    "        \"\"\"\n",
    "        The method to get a random card.\n",
    "\n",
    "        Parameters:\n",
    "            card_name (str): The name of the card to get. If None, a random card is chosen. Default is None.\n",
    "            display (bool): Whether to display the card image. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the card image, card name, and the hulls of the card.\n",
    "        \"\"\"\n",
    "        if card_name is None:\n",
    "            card_name = random.choice(list(self._cards.keys()))\n",
    "        card, hull1, hull2 = self._cards[card_name][random.randint(0, self._nb_cards_by_value[card_name] - 1)]\n",
    "        if display:\n",
    "            display_img(card, [hull1, hull2], \"rgb\")\n",
    "        return card, card_name, hull1, hull2\n",
    "\n",
    "# Create an instance of the Cards class\n",
    "cards = Cards()"
   ],
   "id": "4246dea0927611c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creation of 2-cards and 3-cards scenarios\n",
    " Move on to the creation of 2-card and 3-card scenarios that will then be used to train the model."
   ],
   "id": "613a96008ba026e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from background_random import backgrounds\n",
    "from cards_scenario import Scene\n",
    "\n",
    "# Function to generate scenarios with two cards\n",
    "def generate_scenarios(num_scenarios, save_dir):\n",
    "    \"\"\"\n",
    "    Generate a specified number of scenarios with two cards.\n",
    "\n",
    "    Parameters:\n",
    "    num_scenarios (int): The number of scenarios to generate.\n",
    "    save_dir (str): The directory where the generated scenarios should be saved.\n",
    "    \"\"\"\n",
    "    # Loop over the number of scenarios to generate\n",
    "    for _ in tqdm(range(num_scenarios)):\n",
    "        # Get a random background\n",
    "        bg = backgrounds.get_random()\n",
    "        # Get two random cards\n",
    "        img1, card_val1, hulla1, hullb1 = cards.get_random()\n",
    "        img2, card_val2, hulla2, hullb2 = cards.get_random()\n",
    "        # Create a new scene with the two cards\n",
    "        newimg = Scene(bg, img1, card_val1, hulla1, hullb1, img2, card_val2, hulla2, hullb2)\n",
    "        # Write the new scene to files\n",
    "        newimg.write_files(save_dir)\n",
    "\n",
    "# The directory where the model training data is stored\n",
    "model_training_dir = os.path.join(HOME, \"model_training/\" + dataset_name)\n",
    "# The types of scenarios to generate\n",
    "scenario_types = ['train', 'val', 'test']\n",
    "# The number of scenarios to generate for each type\n",
    "num_scenarios = [14000, 3000, 3000]  # Number of scenarios for train, val, test respectively\n",
    "\n",
    "# Loop over each scenario type\n",
    "for scenario_type, num in zip(scenario_types, num_scenarios):\n",
    "    # The directory where the scenarios of this type should be saved\n",
    "    save_dir = os.path.join(model_training_dir, scenario_type, \"images\")\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # Generate the scenarios\n",
    "    generate_scenarios(num, save_dir)\n",
    "    \n",
    "# Print a message indicating that the scenarios have been generated\n",
    "print(\"Scenarios with 2 cards generated\")"
   ],
   "id": "91161ebc98d2502a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from background_random import backgrounds\n",
    "from cards_scenario import Scene\n",
    "\n",
    "def generate_scenarios(num_scenarios, save_dir):\n",
    "    \"\"\"\n",
    "    Generate a specified number of scenarios with three cards.\n",
    "\n",
    "    Parameters:\n",
    "    num_scenarios (int): The number of scenarios to generate.\n",
    "    save_dir (str): The directory where the generated scenarios should be saved.\n",
    "    \"\"\"\n",
    "    # Loop over the number of scenarios to generate\n",
    "    for _ in tqdm(range(num_scenarios)):\n",
    "        # Get a random background\n",
    "        bg = backgrounds.get_random()\n",
    "        # Get three random cards\n",
    "        img1, card_val1, hulla1, hullb1 = cards.get_random()\n",
    "        img2, card_val2, hulla2, hullb2 = cards.get_random()\n",
    "        img3, card_val3, hulla3, hullb3 = cards.get_random()\n",
    "        # Create a new scene with the three cards\n",
    "        newimg = Scene(bg, img1, card_val1, hulla1, hullb1, img2, card_val2, hulla2, hullb2, img3, card_val3, hulla3, hullb3)\n",
    "        # Write the new scene to files\n",
    "        newimg.write_files(save_dir)\n",
    "\n",
    "# The directory where the model training data is stored\n",
    "model_training_dir = os.path.join(HOME, \"model_training/\" + dataset_name)\n",
    "# The types of scenarios to generate\n",
    "scenario_types = ['train', 'val', 'test']\n",
    "\n",
    "# Loop over each scenario type\n",
    "for scenario_type, num in zip(scenario_types, num_scenarios):\n",
    "    # The directory where the scenarios of this type should be saved\n",
    "    save_dir = os.path.join(model_training_dir, scenario_type, \"images\")\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # Generate the scenarios\n",
    "    generate_scenarios(num, save_dir)\n",
    "\n",
    "# Print a message indicating that the scenarios have been generated\n",
    "print(\"Scenarios with 3 cards generated\")"
   ],
   "id": "2a79ba4685e25892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating labels\n",
    "Creating labels from the xml file of each image Now that we have the scenarios with their respective .xml we can translate them into YOLO txt files and create labels accordingly. We then remove all xml files that are no longer useful."
   ],
   "id": "6f47b7e2fe3c42fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "def create_dir_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Create a directory if it does not already exist.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The path of the directory to create.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"\n",
    "    Run a command in the shell.\n",
    "\n",
    "    Parameters:\n",
    "    command (list): The command to run, as a list of strings.\n",
    "    \"\"\"\n",
    "    subprocess.run(command)\n",
    "\n",
    "# Directories where the labels will be stored\n",
    "labels_dirs = [os.path.join(model_training_dir, \"train/labels\"), os.path.join(model_training_dir, \"val/labels\"),\n",
    "               os.path.join(model_training_dir, \"test/labels\")]\n",
    "\n",
    "# Path to the script that converts VOC annotations to YOLO format\n",
    "convert_voc_yolo_dir = os.path.join(HOME, \"dataset_creation/convert_voc_yolo.py\")\n",
    "\n",
    "# Directories where the images are stored\n",
    "images_dirs = [os.path.join(model_training_dir, \"train/images\"), os.path.join(model_training_dir, \"val/images\"),\n",
    "               os.path.join(model_training_dir, \"test/images\")]\n",
    "\n",
    "# Path to the file containing the names of the cards\n",
    "cards_names_dir = os.path.join(HOME, \"dataset_creation/data/cards.names\")\n",
    "\n",
    "# Commands to run the conversion script for each set of images\n",
    "commands = [\n",
    "    [\"python\", convert_voc_yolo_dir, images_dirs[0], cards_names_dir],\n",
    "    [\"python\", convert_voc_yolo_dir, images_dirs[1], cards_names_dir],\n",
    "    [\"python\", convert_voc_yolo_dir, images_dirs[2], cards_names_dir],\n",
    "]\n",
    "\n",
    "# Run each command\n",
    "for command in commands:\n",
    "    run_command(command)\n",
    "\n",
    "def move_txt_files(source_dir, destination_dir):\n",
    "    \"\"\"\n",
    "    Move all .txt files from one directory to another.\n",
    "\n",
    "    Parameters:\n",
    "    source_dir (str): The directory to move the files from.\n",
    "    destination_dir (str): The directory to move the files to.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            source = os.path.join(source_dir, file_name)\n",
    "            destination = os.path.join(destination_dir, file_name)\n",
    "            shutil.move(source, destination)\n",
    "\n",
    "# Create the labels directories if they do not exist\n",
    "for directory in labels_dirs:\n",
    "    create_dir_if_not_exists(directory)\n",
    "\n",
    "# Move the .txt files to the labels directories\n",
    "for source_dir, destination_dir in zip(images_dirs, labels_dirs):\n",
    "    move_txt_files(source_dir, destination_dir)\n",
    "\n",
    "def delete_xml_files(directory):\n",
    "    \"\"\"\n",
    "    Delete all .xml files in a directory.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory to delete the files from.\n",
    "    \"\"\"\n",
    "    # Get all XML files in the directory\n",
    "    xml_files = glob.glob(os.path.join(directory, '*.xml'))\n",
    "\n",
    "    # Delete each XML file\n",
    "    for xml_file in xml_files:\n",
    "        os.remove(xml_file)\n",
    "\n",
    "# Delete the XML files from the images directories\n",
    "for directory in images_dirs:\n",
    "    delete_xml_files(directory)"
   ],
   "id": "bb0e52fc2d44b62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Your dataset is now ready! \n",
    "**You can now move on to the next step: training the model.**\n",
    "\n",
    "*proceed to the next notebook: [Model Training.ipynb]*"
   ],
   "id": "60e325081fa73f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
